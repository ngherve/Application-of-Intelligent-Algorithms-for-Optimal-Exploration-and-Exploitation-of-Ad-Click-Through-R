/**
 * 
 */
package honours.smartads_agent.models;

import java.util.ArrayList;
import java.util.Random;

import honours.smartads_agent.datareader.DataObjectSoftmax;

/**
 * @author HERVE NG
 *
 */
public class SoftmaxAlgorithm {
	
	private double tau;
	private ArrayList<Integer> counts;

	private ArrayList<Double> values; //average reward for each arm
	private int sumReward;
	//Initialise variables for duration of accumulated simulation (num_sims * horizon_per_simulation)
	private int arms;
	private	int num_Simulations; //Represents the number of independent simulations, each of length equal to ‘horizon’
	private int horizon; //Represents the number of time steps/trials per round of simulation
	private	int numEpsValues;
	private Graph<User> usergraph;

	
	/**
	 * @param tau
	 * @param arms
	 * @param num_Simulations
	 * @param horizon
	 * @param numEpsValues
	 * @param filename
	 */
	public SoftmaxAlgorithm(Graph<User> usergraph, double tau, int arms, 
			int num_Simulations, int horizon) {
		this.usergraph = usergraph;
		//this.users = userlist;
		this.tau = tau;
		this.counts = new ArrayList<>();
		this.values = new ArrayList<>();
		this.num_Simulations = num_Simulations;
		this.horizon = horizon;
		this.numEpsValues = num_Simulations;
		this.arms = arms;
		InitArms(arms);
		//testSimSoftmaxAlgo(algo, numArms, num_Simulations, horizon)
	}
	
	/**
	 * @param numArms
	 */
	public void InitArms(int numArms) {
		counts.clear();
		values.clear();
		//rewPerArm.clear();
		sumReward = 0;
		for(int i = 0; i < numArms; i++) {
			counts.add(0);
			values.add(0.0);
		}
	}
	
	/**
	 * @return
	 */
	private int selectArm() {
		//calculate softmax probabilities based on each round
		ArrayList<Double> probs = new ArrayList<>();
		double sum = 0.0;
		for(int i = 0; i < arms; i++) {
			sum += Math.exp(values.get(i) / tau);
		}
		
		for(int i = 0; i < arms; i++) {
			double exp = Math.exp(values.get(i) / tau);
			double curProb = exp / sum;
			probs.add(curProb);
		}
		
		//use categorical draws to pick arm
		return Categ_Draws(probs);
	}
	
	/**
	 * @param chosen_arm
	 * @param reward
	 */
	private void updateArmRewards(int chosen_arm, int reward) {
		//update counts pulled for the am
		int curCount = counts.get(chosen_arm);
		this.counts.set(chosen_arm, curCount + 1);
		int upCount = counts.get(chosen_arm); //get updated counts
		
		//update average rewards / mean value / reward for chosen arm 
		double value = this.values.get(chosen_arm);
		double newValue = ((upCount - 1) / (float)upCount) * value 
							+ (1 / (float)upCount) * reward;
		this.values.set(chosen_arm, newValue);
	}
	
	//Arm selection based on Softmax probability
	/**
	 * @param probs
	 * @return
	 */
	private int Categ_Draws(ArrayList<Double> probs) {
		Random rand = new Random();
		double z = rand.nextDouble();
		double cumu_prob = 0.0;
		
		for(int i = 0; i < arms; i++) {
			double prob = probs.get(i);
			cumu_prob += prob;
			
			if(cumu_prob > z) {
				return i;
			}
		}
		
		return probs.size() - 1;
	}	
	
	/**
	 * @param algo
	 * @param numArms
	 * @param num_Simulations
	 * @param horizon
	 */
	public DataObjectSoftmax testSimSoftmaxAlgo() {
		//initialising the map object storing data
		//HashMap<ArrayList<Integer>, String> dataMap = new HashMap<>();
		//DefaultCategoryDataset dataset = new DefaultCategoryDataset();
		//ArrayList<Double> aveRew = new ArrayList<>();

		
		int duration = num_Simulations * horizon;
		
		ArrayList<Integer> chosenArms = new ArrayList<>();
		ArrayList<Integer> rewards = new ArrayList<>();
		ArrayList<Integer> cum_Rewards = new ArrayList<>();
		ArrayList<Integer> sim_Numbers = new ArrayList<>();
		ArrayList<Integer> times = new ArrayList<>();
		
		for(int i = 0; i < duration; i++) {
			chosenArms.add(0);
			//System.out.println("here");
			rewards.add(0);
			cum_Rewards.add(0);
			sim_Numbers.add(0);
			times.add(0);
		}

		for(int i = 0; i < num_Simulations; i++) {
			i = i + 1;
			InitArms(arms);
			int j = 0;
			for(User us : usergraph.getAllVertices()) {
				j = j + 1; //time
				int index = (i - 1) * horizon + j - 1;
				sim_Numbers.set(index, i);
				times.set(index, j);
				
				//selection of best arm and engaging it
				int chosenarm = selectArm();
				//System.out.println(chosenarm);

				chosenArms.set(index, chosenarm);
				
				//Engage chosen arm to obtain rewards info

				int reward = us.getAdItems().get(chosenarm).getSelIndex();
				//int reward = File_Reader.readValue(fileData, j, chosenarm);
				rewards.set(index, reward);
				
				sumReward += reward;
				
				if(j == 1) {
					cum_Rewards.set(index, reward);
				}
				else {
					int newIndex = index - 1;
					int newCumRew = cum_Rewards.get(newIndex);
					cum_Rewards.set(index, newCumRew + reward);
				}
				//System.out.println(chosenarm);
				updateArmRewards(chosenarm, reward);
				j++;
				rewards.set(j, sumReward);

			}

			//System.out.println("Counts per arm for simulation: " + i + " = " );
		}
		
		/*dataMap.put(chosenArms, "Chosen arm for various iterations");
		dataMap.put(rewards, "Rewards per iterations");
		dataMap.put(cum_Rewards, "Cumulative Rewards for different iterations");
		dataMap.put(sim_Numbers, "Simulation number per iteration");
		dataMap.put(times, "Times per horizon");*/
		int maxad = EgreedyAlgorithm.findMaxCount(getCounts(), getArms());
		ArrayList<Double> aveRewperIter = UCB_RandAlgorithms.DetAveRewPerIterForBEstArm
													(maxad, chosenArms, num_Simulations);
		DataObjectSoftmax objdata = new DataObjectSoftmax(chosenArms, rewards, cum_Rewards, 
				sim_Numbers, times, getCounts(), getValues(), getSumReward(), aveRewperIter);
		System.out.println("For tau = " + getTau() + "\n" + getCounts());
		System.out.println("Average Rewards" + getValues());
		System.out.println("Sum of Rewards " + getSumReward());		
		
		return objdata;
	}
	
	/**
	 * @return the counts
	 */
	public ArrayList<Integer> getCounts() {
		return counts;
	}

	/**
	 * @param counts the counts to set
	 */
	public void setCounts(ArrayList<Integer> counts) {
		this.counts = counts;
	}

	/**
	 * @return the values
	 */
	public ArrayList<Double> getValues() {
		return values;
	}

	/**
	 * @param values the values to set
	 */
	public void setValues(ArrayList<Double> values) {
		this.values = values;
	}

	/**
	 * @return the sumReward
	 */
	public int getSumReward() {
		return sumReward;
	}

	/**
	 * @param sumReward the sumReward to set
	 */
	public void setSumReward(int sumReward) {
		this.sumReward = sumReward;
	}

	/**
	 * @return the tau
	 */
	public double getTau() {
		return tau;
	}

	/**
	 * @param tau the tau to set
	 */
	public void setTau(double tau) {
		this.tau = tau;
	}

	/**
	 * @return the arms
	 */
	public int getArms() {
		return arms;
	}

	/**
	 * @param arms the arms to set
	 */
	public void setArms(int arms) {
		this.arms = arms;
	}

	/**
	 * @return the num_Simulations
	 */
	public int getNum_Simulations() {
		return num_Simulations;
	}

	/**
	 * @param num_Simulations the num_Simulations to set
	 */
	public void setNum_Simulations(int num_Simulations) {
		this.num_Simulations = num_Simulations;
	}

	/**
	 * @return the horizon
	 */
	public int getHorizon() {
		return horizon;
	}

	/**
	 * @param horizon the horizon to set
	 */
	public void setHorizon(int horizon) {
		this.horizon = horizon;
	}

	/**
	 * @return the numEpsValues
	 */
	public int getNumEpsValues() {
		return numEpsValues;
	}

	/**
	 * @param numEpsValues the numEpsValues to set
	 */
	public void setNumEpsValues(int numEpsValues) {
		this.numEpsValues = numEpsValues;
	}
	
}
